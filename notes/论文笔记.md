---
attachments: [Clipboard_2022-06-15-16-56-31.png, Clipboard_2022-06-15-17-40-02.png, Clipboard_2022-06-16-09-14-23.png, Clipboard_2022-06-16-09-44-24.png, Clipboard_2022-06-16-09-46-03.png, Clipboard_2022-06-16-10-12-23.png, Clipboard_2022-06-16-10-18-41.png, Clipboard_2022-06-16-10-45-15.png, Clipboard_2022-06-17-11-33-21.png, Clipboard_2022-06-20-10-30-01.png, Clipboard_2022-06-20-10-32-58.png, Clipboard_2022-07-06-10-17-16.png, Clipboard_2022-07-06-10-17-40.png, Clipboard_2022-07-08-11-23-23.png, Clipboard_2022-07-08-14-26-42.png]
tags: [实习笔记/联邦学习, 实习笔记/论文]
title: 论文笔记
created: '2022-06-15T08:40:49.425Z'
modified: '2022-07-12T02:21:51.348Z'
---

# [论文笔记](https://www.runoob.com/docker/docker-tutorial.html) 

## Federated Learning: Applications, Challenges and Future Scopes 
### 摘要
联邦学习(FL)是一个中心聚合器协调多个用户解决机器学习问题的系统。此设置允许分散训练数据，以保护隐私。本文的目的是提供一个以医疗保健为重点的 FL 系统的概述。FL 在此基于其框架、体系结构和应用程序进行评估。结果表明，FL 通过一个中央聚合服务器，使用一个共享的全局深度学习(DL)模型解决了前面的问题。本文审查了最近的发展，并提供了一个未解决的问题的综合清单，受到快速增长的外语研究的启发。在 FL 的背景下，描述了几种隐私方法，包括安全的多方计算、同态加密、差分隐私和随机梯度下降。此外，本文还回顾了各种外语学习类别，如水平和垂直外语学习以及联邦迁移学习。本文讨论了 FL 在无线通信、服务推荐、智能医疗诊断系统和医疗保健等方面的应用。我们还提出了现有的 FL 的挑战，如隐私保护，通信成本，系统异构性和不可靠的模型上传的彻底回顾，其次是未来的研究方向。

### 应用
- 无线通信
- 服务推荐 
  - 谷歌键盘
  - 智能医药诊断
- 医疗卫生
### 挑战
- 隐私保护，依然存在泄漏隐私数据的风险
- 通信消耗，FL网络有大量设备构成，需要大量的通信
- 系统异质性，FL网络中各个设备的通信能力、计算能力不同。同一时间内，可能只有一部分设备处于活动状态；一些设备可能故障
- 不可靠的模型上传
- 统计学异质性
- 公平性


## FedILC: Weighted Geometric Mean and Invariant Gradient Covariance for Federated Learning on Non-IID Data

### 摘要

联合学习是一种分布式机器学习方法，它通过将本地计算的参数更新与来自空间分布式客户机筒仓的训练数据聚合起来，使共享服务器模型能够学习。虽然联邦学习在规模和隐私方面都具有优势，但是由于领域转移问题，联邦学习模型无法推广到训练领域中数据分布非 I.I.D 的未知领域。在这项研究中，我们提出了联邦不变学习一致性(FedILC)方法，它利用 Hessians 的梯度协方差和几何平均值来捕获环境的筒仓间和筒仓内的一致性，并解决联邦网络中的域移位问题。基准和现实世界的数据集实验表明，我们提出的算法优于传统的基线和类似的联邦学习算法。这与医疗保健、计算机视觉和物联网(IoT)等领域有关。代码在 https://github.com/mikemikezhu/fedilc 发布。

### 动机
尽管取得了巨大的成就，但联邦学习已经被领域移位问题所窒息，这种问题发生在源节点收集的标记数据与目标节点的未标记数据在统计学上不同时，因此学习模型不能推广到数据分布不一致的领域。

在真实场景中，尽管在不同医院收集的医学放射学图像具有均匀分布的标签，但图像外观(例如对比度和饱和度)可能因医院使用的不同成像机器和协议而有所不同。因此，在这些医院合作培训的疾病检测模型可能无法有效地推广到其他医院的异质性特征分布。

Parascandolo 在他的论文中介绍了 Hessians 的几何平均。在凸二次型情况下，梯度的单元几何均值成功地提高了一致性，但仍然存在一些难题。其中一个重要的障碍是，几何平均值只有在所有符号一致时才能定义，而且几乎不可能计算具有不一致符号的几何平均值，这种不一致符号普遍存在于非凸设置中。基于 Parascandolo 的代码实现，他们采用所有梯度的绝对值来计算几何平均值。在训练过程中，虽然采用了二进制掩模列表，但用绝对值几何平均法计算的梯度仍可能引入偏差。因此，该方法可以进一步改进


### 方法
  Fishr + Inter-Geo 和 Fishr + Intra-Geo，以减轻筒仓间和筒仓内域转移问题。此外，我们还引入了一种新的加权几何平均数方法来计算符号不一致的梯度的几何平均值。
![](@attachment/Clipboard_2022-06-16-09-14-23.png)

#### **weighted geometric mean（加权几何平均）**
![](@attachment/Clipboard_2022-06-16-09-46-03.png)

#### **Fishr and Inter-silo Weighted Geometric Mean**
![](@attachment/Clipboard_2022-06-16-10-12-23.png)
![](@attachment/Clipboard_2022-06-16-10-18-41.png)

#### Fishr+Intra-Geo: Fishr and Intra-silo Weighted Geometric Mean
![](@attachment/Clipboard_2022-06-16-10-45-15.png)

## FLUTE: A SCALABLE, EXTENSIBLE FRAMEWORK FOR HIGH-PERFORMANCE FEDERATED LEARNING SIMULATIONS

### 摘要

本文介绍了“联邦学习实用程序和实验工具”(FLUTE) ，这是一个用于联邦学习研究和离线仿真的高性能开源平台。FLUTE 的目标是实现新的大规模联邦学习算法的快速成型和仿真，包括新的优化、隐私和通信策略。我们描述了 FLUTE 的体系结构，使任意的联邦建模方案得以实现，我们将该平台与其他最先进的平台进行了比较，并且描述了 FLUTE 在活跃研究的核心领域(如优化、隐私和可伸缩性)实验的可用特性。我们通过一系列文本预测和语音识别的实验证明了该平台的有效性，包括增加差分隐私、量化、缩放以及各种优化和联合方法。

## SCAFFOLD: Stochastic Controlled Averaging for Federated Learning

### 摘要
联邦平均(FEDAVG)算法以其简单、通信成本低等优点成为联邦学习的首选算法。然而，尽管最近的研究努力，其表现并不完全了解。当数据是异构(非 iid)时，FEDAVG 存在“客户端漂移”，导致收敛不稳定和缓慢。作为一种解决方案，我们提出了一种新的算法(SCAFFOLD) ，使用控制变量(方差减少) ，以纠正’客户端漂移’在其本地更新。我们证明 SCAFFOLD 需要的通信轮数明显减少，并且不受数据异构性或客户端采样的影响。进一步，我们表明(对于二次函数) SCAFFOLD 可以利用客户端数据的相似性，产生更快的收敛速度。后者是量化分布式优化中局部步长有用性的第一个结果。

### SCAFFOLD
![](@attachment/Clipboard_2022-06-17-11-33-21.png)


## ADAPTIVE FEDERATED OPTIMIZATION

### 摘要
在这项工作中，我们提出了联邦版本的自适应优化器，包括 ADAGRAD，ADAM 和 YOGI，并分析了它们在异构数据存在的一般非凸设置下的收敛性。我们的研究结果强调了客户端异构性和通信效率之间的相互作用。我们还对这些方法进行了广泛的实验，结果表明使用自适应优化器可以显著提高联邦学习的性能

### 动机

FEDAVG 存在的问题：包括(1)客户漂移(Karimireddy 等，2019) ，其中本地客户模型偏离全局最优模型，以及(2)缺乏适应性。FEDAVG 在精神上类似于 SGD，并且可能不适用于具有重尾随机梯度噪声分布的环境，这种情况在训练语言模型时经常出现(Zhang et al。 ，2019a)。

### contribution
- 我们研究了一个使用服务器和客户端优化器的联邦优化通用框架。该框架推广了许多现有的联邦优化方法，包括 FEDAVG。
- 我们使用这个框架来设计新颖的、跨设备兼容的、自适应的联邦优化方法，并提供一般非凸设置下的收敛性分析。据我们所知，这些是使用自适应服务器优化的第一种 FL 方法。我们展示了局部步骤的数量和客户端之间的异构性之间的重要相互作用。
- 我们引入了全面和可重复的经验基准，用于比较联邦优化方法。这些基准测试包括七个不同的和有代表性的任务，涉及图像和文本数据，具有不同数量的异质性和客户端数量。
- 我们展示了我们的自适应优化器的强大的经验性能，改善了常用的基线。我们的研究结果表明，我们的方法可以更容易地进行调优，并突出了它们在跨设备设置中的实用性

### 方法
![](@attachment/Clipboard_2022-06-20-10-32-58.png)
![](@attachment/Clipboard_2022-06-20-10-30-01.png)

## Dynamic Regularization

## Fedbn:..... via local batch normalization

### 摘要
我们提出了一种新的联邦学习方法来分布式训练神经网络模型，其中服务器协调在每一轮随机选择的设备子集之间的合作。我们主要从通信的角度来看待联邦学习问题，允许更多的设备级计算来节省传输成本。我们指出了一个基本的困境，即局部设备水平经验损失的最小值与全局经验损失的最小值不一致。不同于以往的工作，无论是尝试不精确的最小化或利用设备并行梯度计算，我们提出了一个动态正则化为每一个设备在每一轮，使全局和设备的解决方案是一致的。我们通过对实际和合成数据的经验结果以及分析结果证明，我们的方案在凸和非凸设置中都能导致有效的训练，同时对设备异构性完全不可知，对大量设备、部分参与和不平衡数据具有鲁棒性




## Adressing class imbalance in federated Learning 
[link](https://zhuanlan.zhihu.com/p/443009189)

1. 本文设计一个 monitor 来估计 FL 过程中的 composition，如果某个特定的不平衡 composition 连续出现，monitor 会对此产生响应。

2. 本文提出了一种新的损失函数 Ratio Loss 在保证数据隐私安全的前提下，缓解 class imbalance 问题。

在 round [公式] 时，monitor 下载在 round [公式] 时的 global model [公式] ，喂入辅助数据样本。在每个 class 中，monitor 获得相应的梯度更新 [公式] 。将更新与 [公式] 进行比较，monitor 可以在 round [公式] 时获得训练数据的成分。如果连续检测到 similar imbalanced composition，系统确认 global model 已经学习到不平衡数据，然后通过在 FL 中应用 Ratio Loss 来减轻其影响。
## FedMA

## MOON 
魔改FedAvg

## [FedNova](https://arxiv.org/abs/2007.07481)
魔改FedAvg 

在联邦优化中，客户端本地数据集的异构性和计算速度导致每个客户端在每个通信轮中执行的本地更新数量存在很大差异。这些模型的简单加权聚合会导致客观上的不一致，也就是说，全局模型会收敛到一个不匹配的目标函数的驻点，这个目标函数可以任意地与真正的目标不同。本文提供了一个分析联邦异构优化算法收敛性的一般框架。它包含了先前提出的方法，如 FedAvg 和 FedProx，并提供了解决方案偏差和收敛速度减慢由于客观不一致的第一原则的理解。利用这一分析结果，我们提出了一种规范化平均方法—— Fed-Nova，该方法在保持快速误差收敛的同时消除了目标不一致性.
![](@attachment/Clipboard_2022-07-06-10-17-40.png)
![](@attachment/Clipboard_2022-07-06-10-17-16.png)

##  [Federated Learning with Only Positive Labels](https://arxiv.org/abs/2004.10342)
![](@attachment/Clipboard_2022-07-08-11-23-23.png)
![](@attachment/Clipboard_2022-07-08-14-26-42.png)
